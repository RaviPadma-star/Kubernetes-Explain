so we are config the application i am getting some serror i changes some of code in nginx file 
of default.config of web file..

in real time dont use spot instance 
some we need to remove cache means
 -- docker build --no-cache -t padmaravi/web .

 and main while 
 location /api/ratings/ {
        proxy_pass http://ratings:80/;
    }

    we never forget the / after the :80

    note: for rabbit mq need to search for ports they are two ports so we need to mention in manifest file

    after dooing the all config of roboshop!! its a basic termes of kubernated..

    so every time we deleting and creating the pods making issue so for that overcome these we have
    replicasets..
    these will do replica the pods how much we set

    then created a folder called name with replicasets and under that 01-replicasets.ymal file
    in server gp anf cd replicasets and kubetctl apply -f 01-replicaset.yaml

    [ec2-user@ip-172-31-18-63 replicasets]$ kubectl apply -f 01-replicaset.yaml
replicaset.apps/nginx created
[ec2-user@ip-172-31-18-63 replicasets]$ p
NAME          READY   STATUS    RESTARTS   AGE
nginx-57r45   1/1     Running   0          4s
nginx-k5tq2   1/1     Running   0          4s
nginx-kfms6   1/1     Running   0          4s


    [ec2-user@ip-172-31-18-63 replicasets]$ 
    -- kubectl get replicaset

NAME    DESIRED   CURRENT   READY   AGE
nginx   3         3         3       43s
[ec2-user@ip-172-31-18-63 replicasets]$


-------------
nginx-57r45

podname = [replicaset-name]-[random-name]

when ever suddelenly we delete the pod means its automatically create another pod with light speed when set as replica

---------------
now main thing is deplyement comes in kubernates what it does it automaitcally update the latest image when its availbale

--rolling update is nothing but zero downtime of application and also new update should be happen
so when there is deplyemt Running with old and latest some disadvatg\age will ber there to overcome these type we have
rolling update startegy in kubernates

strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 2 # we asked for 10, we are okay if 9 are running at the time of upgrade
      maxSurge: 2 # we asked for 10, we are okay at the time of upgrade 11 are running

-- this is important that rollback and history of delopyment in ci/cd pipile check all cmd in kubernetes officals docs are
see video about it on youtube..


----------------------
volumes:

these are 2 types of volumes -> ebs, and efs this is for aws

and we have :

emptyDir and hostPath

then created a stoarge folder and file with name 01-emptyDir.yaml

then pusg to git , git pull adt server, cd stoarge, kubectl apply -f 01-emptyDir.yaml --> pods created -> kubectl get pods
if we observe in ready status 2/2 is running one is image and sidecar running

so if we want go inside of 2 container we need to give -->
kubectl exec simple-webapp -it -c sidecar-container -- sh

then inside of container --> ls -l
then it give some list

then -> cd /var/log/nginx
-----------------------

mounting config maps as volumes:

create configmap  for files  like nginx.config
mount them as volumes
use it for containers
02-configmaps-volumes-mount-to-web

after that created a sidecar.yaml file to push the logs to elastic search with using filebeats
see -> 03-sidecar-filebeat.yaml

after kubectl apply
tehn go to inside of container
tthen check logs
-------------------------------

daemonSet --> is used for run a pod on every node
usecase: sidecar is used to ship the logs files to elastic search , similarly nodes are running, this node 
will write lot of logs, to analize this logs what we do is we run daemonSet pod

sidecar are to analize the logs of pod, but daemonSet are used for underline the metric of nodes and logs of nodes

==created a file called 04-daemonSet-hostPath.yaml--> afer apply tthe kubectl

--> to check this -> kubectl get pods -n kube-system

--> kubectl get pods -o wide

------------------------
stoarge outside of kubernates of cluster:

this like external hard disk ex: drive/one drive 
this purpose we have PV-> persistant volumes
PVC--> persistant volume claim

static provising -> is ntg but you create a disk and then inform pod -> its called manual process
you need to have  PV -> persistant volume --< it means you declare a volume and pvc is for to claim the volume

lifeCycle policy:
retain --> even your pods is deleted, kubernates will make sure data will not be deleted
delete --> if pods is deleted your data will delete
recycle -> your disk is not deleted, but data is erased


these are static :

access mode :
RWO- READ WRITE ONCE --> IF WE HAVE MULTIPLE PODS, ONLY ONE POD IS ALLOWED TO WRITE, REMANING PODS ARE FOR READ
RWM- READ WRITE MANY  --> ALL PODS CAN READ AND WRITE
RO- READ ONLY --> ONLY FOR READING DATA.

serach in offical docs as access mode-->

in aws we have two types of storages

--> 1. elastic block store

click on instance --> go to securty tab--> you can see IAM role --> click on it while working on to manage the volumes pv and pvc we need to attach a role in IAM user --> go to iam roles and permiison and attach a policy
"ec2FullAccess"

--> creating a hard disk -> click on volume of left side bar once page landed --> click on create volume on top right corner


EBS static provising : 
if ec2 is in one availbale zone, ebs should aslo same zone 
check availbale zone of spot instance and create a volume with same zone

then it created a name called ebs-test--> go to instance 

--> kubectl get stoargeclass (sc)
--> kubectl get pv,pvc
--> kubectl get pv,pvc,pods
------------------------

manual process of creating the sc, pv, pvc and pod

step -1 --> creation of storage class
--------
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: manual
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer


step -2 --> creation of pv
-------------------------------------
apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-ebs-volume
spec:
  storageClassName: manual
  capacity:
    storage: 50Gi
  accessModes:
    - ReadWriteOnce
  awsElasticBlockStore:
    volumeID: vol-0b580a797aa2271c1 #replace volume ID
    fsType: ext4

step -3 --> creation of pvc
--------------------------------------
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-ebs-pvc
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  volumeName: my-ebs-volume

step -4 creation of pod
-------------------------------------------

apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
    - name: my-ebs-volume
      mountPath: /usr/share/nginx/html
  volumes:
  - name: my-ebs-volume
    persistentVolumeClaim:
      claimName: my-ebs-pvc



--> attach the metadata:
            name: my-ebs-volume   -->  to
                                       
                                         resources:
                                            requests:
                                            storage: 10Gi
                                        volumeName: my-ebs-volume    # here the attch the metadata name 

                                        and attach the volume in pods 

                                        volumes:
                                        - name: my-ebs-volume
                                            persistentVolumeClaim:
                                            claimName: my-ebs-pvc

refer 4.md file for dynamic pv, pvc in ebs and efs